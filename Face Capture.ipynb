{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 6 - Face Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1 - Create Training Data\n",
    "\n",
    "# 1st person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:11: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:11: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<ipython-input-1-71088aa84e60>:11: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if faces is ():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples collected\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np \n",
    "\n",
    "face_classifier = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "def face_extractor(img):\n",
    "    \n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_classifier.detectMultiScale(gray, 1.3, 5)\n",
    "    \n",
    "    if faces is ():\n",
    "        return None \n",
    "    \n",
    "    for (x,y,w,h) in faces:\n",
    "        cropped_face = img[y:y+h, x:x+w]\n",
    "    return cropped_face\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "count = 0\n",
    "\n",
    "while True:\n",
    "    \n",
    "    ret, frame = cap.read()\n",
    "    if face_extractor(frame) is not None:\n",
    "        count += 1\n",
    "        face = cv2.resize(face_extractor(frame), (200,200))\n",
    "        face = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        file_name_path = './faces/user/' + str(count) + '.jpg'\n",
    "        cv2.imwrite(file_name_path, face)\n",
    "        \n",
    "        \n",
    "        cv2.putText(face, str(count), (50,50), cv2.FONT_HERSHEY_COMPLEX, 1, (255, 0, 0), 2)\n",
    "        cv2.imshow('Face Cropper', face)\n",
    "        \n",
    "    else:\n",
    "        print(\"Face not found\")\n",
    "        pass\n",
    "    \n",
    "    if cv2.waitKey(1)==13 or count==100:\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "print(\"Samples collected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step2 - Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained succesfully\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import time\n",
    "\n",
    "data_path = './faces/user/'\n",
    "onlyfiles = [f for f in listdir(data_path) if isfile(join(data_path, f))]\n",
    "\n",
    "Training_Data, Labels = [], []\n",
    "\n",
    "for i, files in enumerate(onlyfiles):\n",
    "    image_path = data_path + onlyfiles[i]\n",
    "    images = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    Training_Data.append(np.asarray(images, dtype=np.uint8))\n",
    "    Labels.append(i)\n",
    "    \n",
    "Labels = np.asarray(Labels, dtype=np.int32)\n",
    "\n",
    "harshal_model  = cv2.face_LBPHFaceRecognizer.create()\n",
    "\n",
    "harshal_model.train(np.asarray(Training_Data), np.asarray(Labels))\n",
    "print(\"Model trained succesfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3- Collecting Data and Model for 2nd Person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:13: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:13: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<ipython-input-3-560f64de6721>:13: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if faces is ():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples collected\n",
      "Model trained succesfully\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np \n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "face_classifier = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "def face_extractor(img):\n",
    "    \n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_classifier.detectMultiScale(gray, 1.3, 5)\n",
    "    \n",
    "    if faces is ():\n",
    "        return None \n",
    "    \n",
    "    for (x,y,w,h) in faces:\n",
    "        cropped_face = img[y:y+h, x:x+w]\n",
    "    return cropped_face\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "count = 0\n",
    "\n",
    "while True:\n",
    "    \n",
    "    ret, frame = cap.read()\n",
    "    if face_extractor(frame) is not None:\n",
    "        count += 1\n",
    "        face = cv2.resize(face_extractor(frame), (200,200))\n",
    "        face = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        file_name_path = './faces/user2/' + str(count) + '.jpg'\n",
    "        cv2.imwrite(file_name_path, face)\n",
    "        \n",
    "        \n",
    "        cv2.putText(face, str(count), (50,50), cv2.FONT_HERSHEY_COMPLEX, 1, (255, 0, 0), 2)\n",
    "        cv2.imshow('Face Cropper', face)\n",
    "        \n",
    "    else:\n",
    "        print(\"Face not found\")\n",
    "        pass\n",
    "    \n",
    "    if cv2.waitKey(1)==13 or count==100:\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "print(\"Samples collected\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "data_path = './faces/user2/'\n",
    "onlyfiles = [f for f in listdir(data_path) if isfile(join(data_path, f))]\n",
    "\n",
    "Training_Data, Labels = [], []\n",
    "\n",
    "for i, files in enumerate(onlyfiles):\n",
    "    image_path = data_path + onlyfiles[i]\n",
    "    images = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    Training_Data.append(np.asarray(images, dtype=np.uint8))\n",
    "    Labels.append(i)\n",
    "    \n",
    "Labels = np.asarray(Labels, dtype=np.int32)\n",
    "\n",
    "person_model  = cv2.face_LBPHFaceRecognizer.create()\n",
    "\n",
    "person_model.train(np.asarray(Training_Data), np.asarray(Labels))\n",
    "print(\"Model trained succesfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4- Run the Trained Facial Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:41: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:41: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<ipython-input-4-975d01304eb5>:41: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if faces is ():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instance created...\n",
      "EBS volume of 5GB created...\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import pywhatkit\n",
    "import smtplib, ssl\n",
    "from email.mime.text import MIMEText\n",
    "from email.mime.multipart import MIMEMultipart\n",
    "from email.mime.image import MIMEImage\n",
    "from os.path import isfile, join\n",
    "\n",
    "face_classifier = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "def SendMail(ImgFile):\n",
    "    with open(ImgFile, 'rb') as f:\n",
    "        img_data = f.read()\n",
    "    \n",
    "   \n",
    "    sender_email = \"harshaluser123@gmail.com\"\n",
    "    receiver_email = \"harshalkondhalkar245@gmail.com\"\n",
    "    password = \"idoq12349\"\n",
    "\n",
    "    message = MIMEMultipart()\n",
    "    message[\"Subject\"] = \"System Alert\"\n",
    "    message[\"From\"] = sender_email\n",
    "    message[\"To\"] = receiver_email\n",
    "   \n",
    "    text = MIMEText(\"Hey Harshal, this is your image\")\n",
    "    message.attach(text)\n",
    "    image = MIMEImage(img_data, name=os.path.basename(ImgFile))\n",
    "    message.attach(image)\n",
    "    \n",
    "    \n",
    "    s = smtplib.SMTP_SSL(\"smtp.gmail.com\", 465) \n",
    "    s.login(sender_email, password)\n",
    "    s.sendmail(sender_email, receiver_email, message.as_string())\n",
    "    s.quit()\n",
    "\n",
    "def face_detector(img, size=0.5):\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_classifier.detectMultiScale(gray, 1.3, 5)\n",
    "    if faces is ():\n",
    "        return img, []\n",
    "    \n",
    "    \n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(0,255,255),2)\n",
    "        roi = img[y:y+h, x:x+w]\n",
    "        roi = cv2.resize(roi, (200, 200))\n",
    "    return img, roi\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    image, face = face_detector(frame)\n",
    "    \n",
    "    try:\n",
    "        face = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "       \n",
    "        results = harshal_model.predict(face)\n",
    "       \n",
    "       \n",
    "        \n",
    "        if results[1] < 500:\n",
    "                confidence = int( 100 * (1 - (results[1])/400) )\n",
    "                display_string = str(confidence) + '% Confident it is User'\n",
    "\n",
    "        cv2.putText(image, display_string, (100, 120), cv2.FONT_HERSHEY_COMPLEX, 1, (255,120,150), 2)\n",
    "\n",
    "        if confidence > 80:\n",
    "            cv2.putText(image, \"Hey Harshal\", (250, 450), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 2)\n",
    "            cv2.imshow('Face Recognition', image )\n",
    "            cv2.imwrite('cap_img.jpg', image)\n",
    "\n",
    "            SendMail('cap_img.jpg')\n",
    "            print(\"mail sent\")\n",
    "\n",
    "            pywhatkit.sendwhatmsg('+918080451271', \"Hey Pranav!!!\", 14,10)\n",
    "            print(\"Message sent to Pranav\")\n",
    "            break\n",
    "       \n",
    "                \n",
    "        else:\n",
    "            results = person_model.predict(face)\n",
    "                \n",
    "            if results[1] < 500:\n",
    "                confidence = int( 100 * (1 - (results[1])/400) )\n",
    "                display_string = str(confidence) + '% Confident it is User'\n",
    "\n",
    "            cv2.putText(image, display_string, (100, 120), cv2.FONT_HERSHEY_COMPLEX, 1, (255,120,150), 2)\n",
    "\n",
    "            if confidence > 80:\n",
    "                cv2.putText(image, \"Hey Man\", (250, 450), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 2)\n",
    "                cv2.imshow('Face Recognition', image )\n",
    "                \n",
    "                \n",
    "            \n",
    "                os.system(\"aws ec2 run-instances  --image-id ami-0ad704c126371a549 --instance-type t2.micro --count 1 --subnet-id subnet-7bd28a37 --security-group-ids sg-0a195485ec0f45274 --key-name awsclass2021key\")\n",
    "                print(\"Instance created...\")\n",
    "                os.system(\"aws ec2 create-volume --avaibility-zone ap-south-1b --volume-type gp2 --size 5 \")\n",
    "                print(\"EBS volume of 5GB created...\")\n",
    "                break\n",
    "       \n",
    "        pass\n",
    "    except:\n",
    "        cv2.putText(image, \"No Face Found\", (220, 120) , cv2.FONT_HERSHEY_COMPLEX, 1, (0,0,255), 2)\n",
    "        cv2.putText(image, \"looking for face\", (250, 450), cv2.FONT_HERSHEY_COMPLEX, 1, (0,0,255), 2)\n",
    "        cv2.imshow('Face Recognition', image )\n",
    "        \n",
    "        \n",
    "        \n",
    "    if cv2.waitKey(1) == 13: #13 is the Enter Key\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows() \n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
